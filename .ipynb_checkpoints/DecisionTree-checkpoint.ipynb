{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "Самая простая модель, \"рабочая лошадка\" для теста фич."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 2000) # since we have a lot of features\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import data '''\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "train_file = os.path.join(DATA_DIR, 'train.csv')\n",
    "test_file = os.path.join(DATA_DIR, 'test.csv')\n",
    "submission_file = os.path.join(DATA_DIR, 'sample_submission.csv')\n",
    "\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)\n",
    "\n",
    "X = train.drop(columns=['y', 'sample_id'])\n",
    "y = train.y\n",
    "X_test = test.drop(columns=['sample_id'])\n",
    "\n",
    "X_all = X.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 1777)\n",
      "(766, 932)\n",
      "(766, 1908)\n",
      "(766, 1908)\n",
      "(329, 2518)\n",
      "(329, 1908)\n",
      "(727, 1908)\n"
     ]
    }
   ],
   "source": [
    "''' Gather all preprocessing functions '''\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import bisect\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "''' 1 - divide to training and holdout datasets '''\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, random_state=3, test_size=0.3)\n",
    "\n",
    "''' 2 - define the same validation scheme for all models '''\n",
    "\n",
    "skf = RepeatedStratifiedKFold(n_repeats=5, random_state=17)\n",
    "\n",
    "\n",
    "''' Function 1 - delete all columns with NaN or Inf '''\n",
    "columns_to_keep = X_all.replace([np.inf, -np.inf], np.nan).dropna(axis=1).columns\n",
    "\n",
    "def del_nan(x):\n",
    "    return x[columns_to_keep]\n",
    "delete_nan = FunctionTransformer(del_nan, validate=False)\n",
    "\n",
    "\n",
    "''' Function 2 - delete NaN-only columns '''\n",
    "\n",
    "na_cols = X_all[X_all.isna().any()[lambda x: x].index].isna().agg(['sum', 'count']).T\n",
    "\n",
    "all_na_cols = na_cols[na_cols['sum'] == na_cols['count']]\n",
    "\n",
    "def drop_all_na(X):\n",
    "    ''' Here we drop all columns which consist of NaN only '''\n",
    "    idx = all_na_cols.index.values\n",
    "    return X.drop(columns=idx)\n",
    "\n",
    "drop_all_na_f = FunctionTransformer(drop_all_na, validate=False)\n",
    "\n",
    "\n",
    "''' Function 3 - replace NaN '''\n",
    "\n",
    "has_na_cols = na_cols.T.drop(columns=all_na_cols.index.values).T\n",
    "has_na_cols['perc'] = has_na_cols['sum']/has_na_cols['count']\n",
    "\n",
    "'''def replace_na(X, add_boolean=True, threshold=0.3):\n",
    "    Here we apply two filling strategies\n",
    "            for two types of columns with na:\n",
    "            % na > threshold - fill with mean\n",
    "            % na < threshold - fill with 0.\n",
    "        Plus we add additional columns showing\n",
    "            if the value was na before transformation.\n",
    "    X_copy = X.copy()\n",
    "    cols_less = has_na_cols[has_na_cols['perc'] < threshold].index.values\n",
    "    cols_more = has_na_cols[has_na_cols['perc'] >= threshold].index.values\n",
    "    X_less = X_copy[cols_less]\n",
    "    X_less = X_less.fillna(X_less.mean())\n",
    "    X_copy[cols_less] = X_less\n",
    "    X_copy[cols_more] = X_more\n",
    "    if add_boolean:\n",
    "        was_na = X[has_na_cols.index.values].isna().astype('int64')\n",
    "        was_na.columns = was_na.columns.map(lambda x: x + '_na')\n",
    "        X_copy = pd.concat([X_copy, was_na], axis=1)\n",
    "    return X_copy'''\n",
    "    \n",
    "# I should have checked columns for categorical features before\n",
    "\n",
    "def replace_na(X, add_boolean=True):\n",
    "    ''' Here we apply mean filling strategy.\n",
    "        And add additional columns showing if the values\n",
    "        was na before transformation.\n",
    "    '''\n",
    "    X_copy = X.copy()\n",
    "    cols = has_na_cols.index.values\n",
    "    X_c = X_copy[cols]\n",
    "    X_c = X_c.fillna(X_all.replace([np.inf, -np.inf], np.nan).mean())\n",
    "    X_copy[cols] = X_c\n",
    "    if add_boolean:\n",
    "        was_na = X[has_na_cols.index.values].isna().astype('int64')\n",
    "        was_na.columns = was_na.columns.map(lambda x: x + '_na')\n",
    "        X_copy = pd.concat([X_copy, was_na], axis=1)\n",
    "    return X_copy\n",
    "\n",
    "replace_na_f = FunctionTransformer(replace_na, validate=False)\n",
    "\n",
    "\n",
    "''' Function 4 - replace inf '''\n",
    "\n",
    "pos_inf_cols = X_all.fillna(0).replace([np.inf], \n",
    "                                       np.nan).isna().any()[lambda x: x].index\n",
    "pos_inf_cols = X_all[pos_inf_cols].replace([np.inf], \n",
    "                                           np.nan).isna().agg(['sum', 'count']).T\n",
    "neg_inf_cols = X_all.fillna(0).replace([-np.inf],\n",
    "                                       np.nan).isna().any()[lambda x: x].index\n",
    "\n",
    "def fill_inf(X, add_boolean=True, multiplier=2):\n",
    "    '''\n",
    "    Here we apply filling strategy for infinite values:\n",
    "        we replace it with absolute maximum value * multiplier.\n",
    "    Additionally, we new columns showing if the value\n",
    "        was infinite before filling.\n",
    "    '''\n",
    "    X_copy = X.copy()\n",
    "    X_pos = X_copy[pos_inf_cols.index.values]\n",
    "    to_fill = X_pos.replace(np.inf, np.nan).abs().max() * multiplier + 1.0\n",
    "    X_pos = X_pos.replace(np.inf, np.nan).fillna(to_fill)\n",
    "    X_copy[pos_inf_cols.index.values] = X_pos\n",
    "    if add_boolean:\n",
    "        was_inf = X[pos_inf_cols.index.values].replace(np.inf, np.nan).isna().astype('int64')\n",
    "        was_inf.columns = was_inf.columns.map(lambda x: x + '_inf')\n",
    "        X_copy = pd.concat([X_copy, was_inf], axis=1)\n",
    "    return X_copy\n",
    "\n",
    "fill_inf_f = FunctionTransformer(fill_inf, validate=False)\n",
    "\n",
    "\n",
    "''' First block of data cleaning is gathered in one function '''\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "\n",
    "''' Function and class 5 - delete zero-variance features '''\n",
    "\n",
    "w = fill_inf(replace_na(drop_all_na(X_all))).var()\n",
    "zero_var_cols = w[np.isclose(w, 0)]\n",
    "\n",
    "def drop_zero_var(X):\n",
    "    idx = zero_var_cols.index.values\n",
    "    return X.drop(columns=idx)\n",
    "\n",
    "drop_zero_var_f = FunctionTransformer(drop_zero_var)\n",
    "\n",
    "class Drop_zero_var:\n",
    "    def __init__(self):\n",
    "        self.zero_var_cols = []\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        w = X.var()\n",
    "        self.zero_var_cols = w[np.isclose(w, 0.0)].index.values\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        return X_copy.drop(columns=self.zero_var_cols)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Drop_zero_var().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "\n",
    "''' Function and class 6 - drop highly correlated features '''\n",
    "\n",
    "'''\n",
    "# Here is the function\n",
    "print(drop_zero_var(pre_proc(X_all)).shape)\n",
    "corr_matrix = pre_proc(X_all).corr().abs()\n",
    "print(corr_matrix.shape)\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(len(to_drop))\n",
    "\n",
    "'''\n",
    "\n",
    "class Drop_corr:\n",
    "    def __init__(self, threshold=0.95):\n",
    "        self.to_drop = []\n",
    "        self.is_fitted = False\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        self.to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        return X_copy.drop(columns=self.to_drop)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Drop_corr().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "    \n",
    "''' Class 7 - encode categorical labels '''\n",
    "\n",
    "class LE_df:\n",
    "    def __init__(self, threshold=5):\n",
    "        self.le_dict = {}\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        categorical = X_copy[counts[counts <= self.threshold].index]\n",
    "        for col in categorical.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(categorical[col])\n",
    "            self.le_dict[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.le_dict.keys():\n",
    "            X_copy[col] = X_copy[col].map(lambda s: -100500 if s not in \\\n",
    "                                          self.le_dict[col].classes_ else s)\n",
    "            if np.any(X_copy[col]==-100500):\n",
    "                le_classes = self.le_dict[col].classes_.tolist()\n",
    "                le_classes.append(-100500)\n",
    "                self.le_dict[col].classes_ = np.asarray(le_classes)\n",
    "            X_copy[col] = self.le_dict[col].transform(X_copy[col])\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "print(LE_df().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "    \n",
    "''' Class 8 - target mean encode categorical labels '''\n",
    "\n",
    "class LOOTME_df:\n",
    "    ''' Class performs leave-one-out target mean encoding '''\n",
    "    def __init__(self, threshold=5):\n",
    "        self.threshold = threshold\n",
    "        self.tme_dict = {}\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_copy = X.copy()\n",
    "        y_copy = y.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        categorical = X_copy[counts[counts <= self.threshold].index]\n",
    "        for col in categorical.columns:\n",
    "            df = pd.concat((X_copy[col], y_copy), axis=1)\n",
    "            df.columns = ['col', 'y']\n",
    "            tme = {}\n",
    "            for value in df['col'].unique():\n",
    "                y_val = df[df['col'] == value]['y'].values\n",
    "                col_val = df[df['col'] == value]['col'].values\n",
    "                loo_mean = np.mean((np.full_like(col_val, y_val.sum()) - y_val) / y_val.shape[0])\n",
    "                tme[value] = loo_mean\n",
    "            self.tme_dict[col] = tme\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.tme_dict.keys():\n",
    "            X_copy[col] = X_copy[col].map(lambda s: -100500 if s not in self.tme_dict[col].keys() else s)\n",
    "            self.tme_dict[col][-100500] = 0.0\n",
    "            X_copy[col] = X_copy[col].map(self.tme_dict[col])\n",
    "        return X_copy\n",
    "        \n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "print(LOOTME_df().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "\n",
    "\n",
    "''' Class 9 - One Hot Encoding of categorical features '''\n",
    "\n",
    "class OneHot_df:\n",
    "    def __init__(self, threshold=5, drop_collinear=False):\n",
    "        self.threshold = threshold\n",
    "        self.drop_collinear = drop_collinear\n",
    "        self.categorical = []\n",
    "        self.ohe = None\n",
    "        self.column_names = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        X_cat = X_copy[counts[(counts <= self.threshold) & (counts > 1)].index]\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        ohe.fit(X_cat)\n",
    "        self.categorical = X_cat.columns\n",
    "        self.ohe = ohe\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_cat = X_copy.copy()[self.categorical]\n",
    "        X_cat_tr = self.ohe.transform(X_cat).toarray()\n",
    "        if not self.column_names:\n",
    "            column_names = []\n",
    "            for i, col in enumerate(self.categorical):\n",
    "                column_names.extend([col + '_' + str(s) for s in self.ohe.categories_[i]])\n",
    "            self.column_names = column_names\n",
    "        X_cat_tr = pd.DataFrame(X_cat_tr, columns=self.column_names, index=X_copy.index)\n",
    "        X_other = X_copy.drop(columns=self.categorical)\n",
    "        X_copy = pd.concat([X_other, X_cat_tr], axis=1)\n",
    "        if self.drop_collinear:\n",
    "            to_drop = pd.Series(self.column_names, \n",
    "        index=self.column_names).apply(lambda x: x.endswith('_0'))[lambda x: x].index\n",
    "            X_copy.drop(columns=to_drop)\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(OneHot_df().fit(pre_proc(X_train)).transform(pre_proc(X_hold)).shape)\n",
    "\n",
    "''' Class 10 - find best normalizing transformation '''\n",
    "\n",
    "def get_shapiro_p(X):\n",
    "    _, p = shapiro(X)\n",
    "    return p\n",
    "\n",
    "class Find_Trans:\n",
    "    def __init__(self, threshold=10):\n",
    "        self.threshold = threshold\n",
    "        self.pvals = []\n",
    "        self.numerical = []\n",
    "        self.is_fitted = False\n",
    "        self.mms = MinMaxScaler()\n",
    "        self.trans_dict = {'no': lambda x: x,\n",
    "                           'x^2': lambda x: np.power(x, 2), \n",
    "                           'x^3': lambda x: np.power(x, 3), \n",
    "                           'log(x)': lambda x: np.log(x), \n",
    "                           #'exp(x)': lambda x: np.exp(x/10), \n",
    "                           'sqrt(x)': lambda x: np.sqrt(x)}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        self.numerical = counts[counts > self.threshold].index.values\n",
    "        X_numer = X_copy[self.numerical]\n",
    "        idx = X_numer.index\n",
    "        X_numer = pd.DataFrame(self.mms.fit_transform(X_numer) + 0.01,\n",
    "                               columns=self.numerical,\n",
    "                               index=idx)\n",
    "        pvals = pd.DataFrame(X_numer.apply(get_shapiro_p), columns=['no'])\n",
    "        for name in self.trans_dict.keys():\n",
    "            if name not in pvals.columns:\n",
    "                pvals[name] = X_numer.apply(self.trans_dict[name]).apply(get_shapiro_p)\n",
    "        self.pvals = pvals\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_numer = X_copy[self.numerical]\n",
    "        idx = X_numer.index\n",
    "        X_numer = pd.DataFrame(self.mms.transform(X_numer) + 0.01,\n",
    "                               columns=self.numerical,\n",
    "                               index=idx)\n",
    "        best_transform = self.pvals.idxmax(axis=1)\n",
    "        best_transform = best_transform.map(self.trans_dict).to_dict()\n",
    "        X_numer = X_numer.apply(best_transform)\n",
    "        X_numer = X_numer.fillna(X_numer.min()-1)\n",
    "        for col in self.numerical:\n",
    "            X_copy[col] = X_numer[col]\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Find_Trans().fit(pre_proc(X_train), y_train).transform(pre_proc(X_hold)).shape)\n",
    "\n",
    "\n",
    "''' Class 11 - find and drop outliers '''\n",
    "\n",
    "class DetectOut_df:\n",
    "    def __init__(self, method='IsolationForest', out_fraction=0.05, \n",
    "                 drop=True, random_state=17,\n",
    "                 kernel='rbf', shrink=True):\n",
    "        self.method = method\n",
    "        self.out_fraction = out_fraction\n",
    "        self.drop = drop\n",
    "        self.is_fitted = False\n",
    "        self.random_state = random_state\n",
    "        self.kernel = kernel\n",
    "        self.shrink = shrink\n",
    "        self.model = None\n",
    "        self.train_set = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.method == 'IsolationForest':\n",
    "            model = IsolationForest(random_state=self.random_state,\n",
    "                        n_estimators=100,\n",
    "                        max_features=0.9,\n",
    "                        contamination=self.out_fraction, #\n",
    "                        n_jobs=-1,\n",
    "                        behaviour='new')\n",
    "        if self.method == 'OneClassSVM':\n",
    "            model = OneClassSVM(kernel=self.kernel,\n",
    "                     nu=self.out_fraction,\n",
    "                     shrinking=self.shrink,\n",
    "                     gamma='scale'\n",
    "                    )\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        self.is_fitted = True\n",
    "        self.train_set = X.copy()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        ''' We shouldn't predict any outliers for test set '''\n",
    "        X_copy = X.copy()\n",
    "        X_copy['outlier'] = 1\n",
    "        X_copy['y'] = y.copy()\n",
    "        if self.train_set.equals(X):\n",
    "            X_copy['outlier'] = self.model.predict(X)\n",
    "        if self.drop:\n",
    "            X_copy = X_copy[X_copy['outlier'] == 1]\n",
    "            X_copy = X_copy.drop(columns=['outlier'])\n",
    "        y_copy = X_copy['y']\n",
    "        X_copy = X_copy.drop(columns=['y'])\n",
    "        return X_copy, y_copy\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "print(DetectOut_df().fit_transform(pre_proc(X_train), y_train)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набор преобразований 1 - удаление всех колонок с Nan и Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 1.0000\n",
      "Cross-validation ROC AUC: mean 0.6916, std 0.0330\n",
      "Holdout ROC AUC: 0.6646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "pipe_tree = Pipeline([('drop_na', delete_nan),\n",
    "                     ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC -0.786 params {'max_depth': 4.0, 'max_features': 1000.0, 'min_samples_leaf': 15.0}\n",
      "CPU times: user 12.4 s, sys: 1.28 s, total: 13.7 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_iter = 50\n",
    "random_state = 17\n",
    "\n",
    "from hyperopt import fmin, Trials, hp, tpe\n",
    "\n",
    "def tree_roc_cv(params, random_state=random_state, cv=skf, X=X_train, y=y_train):\n",
    "    # the function gest a set of variable parameters in \"param\"\n",
    "    params = {'min_samples_leaf': int(params['min_samples_leaf']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "              'max_features': int(params['max_features'])}\n",
    "    \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = Pipeline([('drop_na', delete_nan),\n",
    "                      ('tree', DecisionTreeClassifier(random_state=random_state, \n",
    "                                                      **params))])\n",
    "    \n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# possible values of parameters\n",
    "space={'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 15, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "       'max_features': hp.quniform('max_features', 10, 1150, 10)\n",
    "      }\n",
    "\n",
    "# trials will contain logging information\n",
    "trials = Trials()\n",
    "\n",
    "\n",
    "best=fmin(fn=tree_roc_cv, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n",
    "         )\n",
    "\n",
    "# computing the score on the test set\n",
    "model = Pipeline([('drop_na', delete_nan),\n",
    "                      ('tree', DecisionTreeClassifier(random_state=random_state, \n",
    "                               min_samples_leaf=int(best['min_samples_leaf']),\n",
    "                               max_depth=int(best['max_depth']),\n",
    "                               max_features=int(best['max_features'])))])\n",
    "model.fit(X_train, y_train)\n",
    "tpe_test_score = roc_auc_score(y_hold, model.predict_proba(X_hold)[:, 1])\n",
    "\n",
    "print(\"Best ROC-AUC {:.3f} params {}\".format( tree_roc_cv(best), best))\n",
    "# best parameters: min_samples_leaf=15, max_depth=4, max_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "\n",
    "submission = pd.read_csv(submission_file)\n",
    "submission['y'] = model.predict_proba(X_test)\n",
    "submission.to_csv('baseline_delete_nan_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка NaN, inf, удаление фич с нулевой дисперсией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 1.0000\n",
      "Cross-validation ROC AUC: mean 0.6975, std 0.0378\n",
      "Holdout ROC AUC: 0.7007\n"
     ]
    }
   ],
   "source": [
    "''' Проверим качество простого дерева на новых фичах '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "\n",
    "def pre_proc(X):\n",
    "    return drop_zero_var(fill_inf(replace_na(drop_all_na(X))))\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 1.0000\n",
      "Cross-validation ROC AUC: mean 0.7060, std 0.0326\n",
      "Holdout ROC AUC: 0.7304\n"
     ]
    }
   ],
   "source": [
    "''' Проверим качество простого дерева на новых фичах без генерации фич-флагов '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "\n",
    "def pre_proc(X):\n",
    "    return drop_zero_var(fill_inf(replace_na(drop_all_na(X), \n",
    "                                             add_boolean=False), \n",
    "                                  add_boolean=False))\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование категориальных фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 1.0000\n",
      "Cross-validation ROC AUC: mean 0.7071, std 0.0300\n",
      "Holdout ROC AUC: 0.7261\n"
     ]
    }
   ],
   "source": [
    "''' Проверим качество простого дерева на новых фичах '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.95\n",
    "CAT_THRESHOLD = 10 # <- and less unique values make feature categorical\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      #('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 1.0000\n",
      "Cross-validation ROC AUC: mean 0.6965, std 0.0317\n",
      "Holdout ROC AUC: 0.7083\n"
     ]
    }
   ],
   "source": [
    "''' Добавим Leave-one-out encoding '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.95\n",
    "CAT_THRESHOLD = 10 # <- and less unique values make feature categorical\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.8817\n",
      "Cross-validation ROC AUC: mean 0.7789, std 0.0431\n",
      "Holdout ROC AUC: 0.8015\n"
     ]
    }
   ],
   "source": [
    "''' Попробуем хорошее дерево и LOO-TME энкодинг '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,\n",
    "                              max_features=0.9,\n",
    "                              min_samples_leaf=15,\n",
    "                              random_state=17)\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop correlated features threshold - 0.94\n",
    "\n",
    "CORR_THRESHOLD = [0.95, 0.97, 0.93, 94]\n",
    "\n",
    "CV_ROC_AUC = [0.7818, 0.7781, 0.7888, 0.7878]\n",
    "\n",
    "HOLD_ROC_AUC = [0.7922, 0.7875, 0.7607, 0.7981]\n",
    "\n",
    "### LOOTME category threshold - 5\n",
    "\n",
    "CAT_THRESHOLD = [10, 0, 5, 15, 20, 8, 3]\n",
    "\n",
    "CV_ROC_AUC = [0.7878, 0.7727, 0.7789, 0.7879, 0.7878, 0.7890, 0.7727]\n",
    "\n",
    "HOLD_ROC_AUC = [0.7981, 0.7734, 0.8015, 0.7981, 0.7981, 0.7981, 0.7734]\n",
    "\n",
    "\n",
    "Неплохие фичи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трансформация фич - лучшая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.8817\n",
      "Cross-validation ROC AUC: mean 0.7787, std 0.0428\n",
      "Holdout ROC AUC: 0.8015\n"
     ]
    }
   ],
   "source": [
    "# Лучшая модель этого класса - 0.85277 на тесте\n",
    "\n",
    "''' Попробуем трансформацию фич на хорошем дереве '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,\n",
    "                              max_features=0.9,\n",
    "                              min_samples_leaf=15,\n",
    "                              random_state=17)\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc1', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('transform', Find_Trans(threshold=CAT_THRESHOLD)),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree.fit(X, y)\n",
    "\n",
    "submission = pd.read_csv(submission_file)\n",
    "submission['y'] = pipe_tree.predict_proba(X_test)[:,1]\n",
    "submission.to_csv('submission_tree_transform.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.8817\n",
      "Cross-validation ROC AUC: mean 0.7787, std 0.0428\n",
      "Holdout ROC AUC: 0.8015\n"
     ]
    }
   ],
   "source": [
    "''' Добавляем стандартизацию фич (всех) '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,\n",
    "                              max_features=0.9,\n",
    "                              min_samples_leaf=15,\n",
    "                              random_state=17)\n",
    "\n",
    "pipe_tree = Pipeline([('pre_proc1', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('transform', Find_Trans(threshold=CAT_THRESHOLD)),\n",
    "                      ('sc', StandardScaler()),\n",
    "                      ('tree', tree)])\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(pipe_tree, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_tree.predict_proba(X_train)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_tree.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.8764\n",
      "Cross-validation ROC AUC: mean 0.7703, std 0.0438\n",
      "Holdout ROC AUC: 0.7397\n"
     ]
    }
   ],
   "source": [
    "''' Our best tree without outliers '''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "OUT_FRACTION = 0.05\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4,\n",
    "                              max_features=0.9,\n",
    "                              min_samples_leaf=15,\n",
    "                              random_state=17)\n",
    "\n",
    "pipe_pre = Pipeline([('pre_proc1', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('transform', Find_Trans(threshold=CAT_THRESHOLD))])\n",
    "\n",
    "X_train_pre = pipe_pre.fit_transform(X_train, y_train)\n",
    "X_train_pre, y_train_pre = DetectOut_df(out_fraction=OUT_FRACTION).fit_transform(X_train_pre,\n",
    "                                                                                 y_train)\n",
    "X_hold_pre = pipe_pre.transform(X_hold)\n",
    "\n",
    "\n",
    "tree.fit(X_train_pre, y_train_pre)\n",
    "\n",
    "scores = cross_val_score(tree, X_train_pre, y_train_pre, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train_pre, tree.predict_proba(X_train_pre)[:,1]))\n",
    "print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, tree.predict_proba(X_hold_pre)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая простая модель этого класса выдала 0.85777 на тесте, 0.7787 на кросс-валидации и 0.8015 на отложенной выборке. Не вошла в финальный блендинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
