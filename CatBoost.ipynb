{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 2000) # since we have a lot of features\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import data '''\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "train_file = os.path.join(DATA_DIR, 'train.csv')\n",
    "test_file = os.path.join(DATA_DIR, 'test.csv')\n",
    "submission_file = os.path.join(DATA_DIR, 'sample_submission.csv')\n",
    "\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)\n",
    "\n",
    "X = train.drop(columns=['y', 'sample_id'])\n",
    "y = train.y\n",
    "X_test = test.drop(columns=['sample_id'])\n",
    "\n",
    "X_all = X.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 1777)\n",
      "(766, 932)\n",
      "(766, 1908)\n",
      "(766, 1908)\n",
      "(329, 2518)\n",
      "(329, 1908)\n",
      "(727, 1908)\n"
     ]
    }
   ],
   "source": [
    "''' Gather all preprocessing functions '''\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import bisect\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "''' 1 - divide to training and holdout datasets '''\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, random_state=3, test_size=0.3)\n",
    "\n",
    "''' 2 - define the same validation scheme for all models '''\n",
    "\n",
    "skf = RepeatedStratifiedKFold(n_repeats=5, random_state=17)\n",
    "\n",
    "\n",
    "''' Function 1 - delete all columns with NaN or Inf '''\n",
    "columns_to_keep = X_all.replace([np.inf, -np.inf], np.nan).dropna(axis=1).columns\n",
    "\n",
    "def del_nan(x):\n",
    "    return x[columns_to_keep]\n",
    "delete_nan = FunctionTransformer(del_nan, validate=False)\n",
    "\n",
    "\n",
    "''' Function 2 - delete NaN-only columns '''\n",
    "\n",
    "na_cols = X_all[X_all.isna().any()[lambda x: x].index].isna().agg(['sum', 'count']).T\n",
    "\n",
    "all_na_cols = na_cols[na_cols['sum'] == na_cols['count']]\n",
    "\n",
    "def drop_all_na(X):\n",
    "    ''' Here we drop all columns which consist of NaN only '''\n",
    "    idx = all_na_cols.index.values\n",
    "    return X.drop(columns=idx)\n",
    "\n",
    "drop_all_na_f = FunctionTransformer(drop_all_na, validate=False)\n",
    "\n",
    "\n",
    "''' Function 3 - replace NaN '''\n",
    "\n",
    "has_na_cols = na_cols.T.drop(columns=all_na_cols.index.values).T\n",
    "has_na_cols['perc'] = has_na_cols['sum']/has_na_cols['count']\n",
    "\n",
    "'''def replace_na(X, add_boolean=True, threshold=0.3):\n",
    "    Here we apply two filling strategies\n",
    "            for two types of columns with na:\n",
    "            % na > threshold - fill with mean\n",
    "            % na < threshold - fill with 0.\n",
    "        Plus we add additional columns showing\n",
    "            if the value was na before transformation.\n",
    "    X_copy = X.copy()\n",
    "    cols_less = has_na_cols[has_na_cols['perc'] < threshold].index.values\n",
    "    cols_more = has_na_cols[has_na_cols['perc'] >= threshold].index.values\n",
    "    X_less = X_copy[cols_less]\n",
    "    X_less = X_less.fillna(X_less.mean())\n",
    "    X_copy[cols_less] = X_less\n",
    "    X_copy[cols_more] = X_more\n",
    "    if add_boolean:\n",
    "        was_na = X[has_na_cols.index.values].isna().astype('int64')\n",
    "        was_na.columns = was_na.columns.map(lambda x: x + '_na')\n",
    "        X_copy = pd.concat([X_copy, was_na], axis=1)\n",
    "    return X_copy'''\n",
    "    \n",
    "# I should have checked columns for categorical features before\n",
    "\n",
    "def replace_na(X, add_boolean=True):\n",
    "    ''' Here we apply mean filling strategy.\n",
    "        And add additional columns showing if the values\n",
    "        was na before transformation.\n",
    "    '''\n",
    "    X_copy = X.copy()\n",
    "    cols = has_na_cols.index.values\n",
    "    X_c = X_copy[cols]\n",
    "    X_c = X_c.fillna(X_all.replace([np.inf, -np.inf], np.nan).mean())\n",
    "    X_copy[cols] = X_c\n",
    "    if add_boolean:\n",
    "        was_na = X[has_na_cols.index.values].isna().astype('int64')\n",
    "        was_na.columns = was_na.columns.map(lambda x: x + '_na')\n",
    "        X_copy = pd.concat([X_copy, was_na], axis=1)\n",
    "    return X_copy\n",
    "\n",
    "replace_na_f = FunctionTransformer(replace_na, validate=False)\n",
    "\n",
    "\n",
    "''' Function 4 - replace inf '''\n",
    "\n",
    "pos_inf_cols = X_all.fillna(0).replace([np.inf], \n",
    "                                       np.nan).isna().any()[lambda x: x].index\n",
    "pos_inf_cols = X_all[pos_inf_cols].replace([np.inf], \n",
    "                                           np.nan).isna().agg(['sum', 'count']).T\n",
    "neg_inf_cols = X_all.fillna(0).replace([-np.inf],\n",
    "                                       np.nan).isna().any()[lambda x: x].index\n",
    "\n",
    "def fill_inf(X, add_boolean=True, multiplier=2):\n",
    "    '''\n",
    "    Here we apply filling strategy for infinite values:\n",
    "        we replace it with absolute maximum value * multiplier.\n",
    "    Additionally, we new columns showing if the value\n",
    "        was infinite before filling.\n",
    "    '''\n",
    "    X_copy = X.copy()\n",
    "    X_pos = X_copy[pos_inf_cols.index.values]\n",
    "    to_fill = X_pos.replace(np.inf, np.nan).abs().max() * multiplier + 1.0\n",
    "    X_pos = X_pos.replace(np.inf, np.nan).fillna(to_fill)\n",
    "    X_copy[pos_inf_cols.index.values] = X_pos\n",
    "    if add_boolean:\n",
    "        was_inf = X[pos_inf_cols.index.values].replace(np.inf, np.nan).isna().astype('int64')\n",
    "        was_inf.columns = was_inf.columns.map(lambda x: x + '_inf')\n",
    "        X_copy = pd.concat([X_copy, was_inf], axis=1)\n",
    "    return X_copy\n",
    "\n",
    "fill_inf_f = FunctionTransformer(fill_inf, validate=False)\n",
    "\n",
    "\n",
    "''' First block of data cleaning is gathered in one function '''\n",
    "\n",
    "def pre_proc(X):\n",
    "    return fill_inf(replace_na(drop_all_na(X)))\n",
    "\n",
    "\n",
    "''' Function and class 5 - delete zero-variance features '''\n",
    "\n",
    "w = fill_inf(replace_na(drop_all_na(X_all))).var()\n",
    "zero_var_cols = w[np.isclose(w, 0)]\n",
    "\n",
    "def drop_zero_var(X):\n",
    "    idx = zero_var_cols.index.values\n",
    "    return X.drop(columns=idx)\n",
    "\n",
    "drop_zero_var_f = FunctionTransformer(drop_zero_var)\n",
    "\n",
    "class Drop_zero_var:\n",
    "    def __init__(self):\n",
    "        self.zero_var_cols = []\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        w = X.var()\n",
    "        self.zero_var_cols = w[np.isclose(w, 0.0)].index.values\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        return X_copy.drop(columns=self.zero_var_cols)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Drop_zero_var().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "\n",
    "''' Function and class 6 - drop highly correlated features '''\n",
    "\n",
    "'''\n",
    "# Here is the function\n",
    "print(drop_zero_var(pre_proc(X_all)).shape)\n",
    "corr_matrix = pre_proc(X_all).corr().abs()\n",
    "print(corr_matrix.shape)\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(len(to_drop))\n",
    "\n",
    "'''\n",
    "\n",
    "class Drop_corr:\n",
    "    def __init__(self, threshold=0.95):\n",
    "        self.to_drop = []\n",
    "        self.is_fitted = False\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        self.to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        return X_copy.drop(columns=self.to_drop)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Drop_corr().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "    \n",
    "''' Class 7 - encode categorical labels '''\n",
    "\n",
    "class LE_df:\n",
    "    def __init__(self, threshold=5):\n",
    "        self.le_dict = {}\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        categorical = X_copy[counts[counts <= self.threshold].index]\n",
    "        for col in categorical.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(categorical[col])\n",
    "            self.le_dict[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.le_dict.keys():\n",
    "            X_copy[col] = X_copy[col].map(lambda s: -100500 if s not in \\\n",
    "                                          self.le_dict[col].classes_ else s)\n",
    "            if np.any(X_copy[col]==-100500):\n",
    "                le_classes = self.le_dict[col].classes_.tolist()\n",
    "                le_classes.append(-100500)\n",
    "                self.le_dict[col].classes_ = np.asarray(le_classes)\n",
    "            X_copy[col] = self.le_dict[col].transform(X_copy[col])\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "print(LE_df().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "    \n",
    "''' Class 8 - target mean encode categorical labels '''\n",
    "\n",
    "class LOOTME_df:\n",
    "    ''' Class performs leave-one-out target mean encoding '''\n",
    "    def __init__(self, threshold=5):\n",
    "        self.threshold = threshold\n",
    "        self.tme_dict = {}\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_copy = X.copy()\n",
    "        y_copy = y.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        categorical = X_copy[counts[counts <= self.threshold].index]\n",
    "        for col in categorical.columns:\n",
    "            df = pd.concat((X_copy[col], y_copy), axis=1)\n",
    "            df.columns = ['col', 'y']\n",
    "            tme = {}\n",
    "            for value in df['col'].unique():\n",
    "                y_val = df[df['col'] == value]['y'].values\n",
    "                col_val = df[df['col'] == value]['col'].values\n",
    "                loo_mean = np.mean((np.full_like(col_val, y_val.sum()) - y_val) / y_val.shape[0])\n",
    "                tme[value] = loo_mean\n",
    "            self.tme_dict[col] = tme\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.tme_dict.keys():\n",
    "            X_copy[col] = X_copy[col].map(lambda s: -100500 if s not in self.tme_dict[col].keys() else s)\n",
    "            self.tme_dict[col][-100500] = 0.0\n",
    "            X_copy[col] = X_copy[col].map(self.tme_dict[col])\n",
    "        return X_copy\n",
    "        \n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "print(LOOTME_df().fit_transform(pre_proc(X_train), y_train).shape)\n",
    "\n",
    "\n",
    "''' Class 9 - One Hot Encoding of categorical features '''\n",
    "\n",
    "class OneHot_df:\n",
    "    def __init__(self, threshold=5, drop_collinear=False):\n",
    "        self.threshold = threshold\n",
    "        self.drop_collinear = drop_collinear\n",
    "        self.categorical = []\n",
    "        self.ohe = None\n",
    "        self.column_names = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        X_cat = X_copy[counts[(counts <= self.threshold) & (counts > 1)].index]\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        ohe.fit(X_cat)\n",
    "        self.categorical = X_cat.columns\n",
    "        self.ohe = ohe\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_cat = X_copy.copy()[self.categorical]\n",
    "        X_cat_tr = self.ohe.transform(X_cat).toarray()\n",
    "        if not self.column_names:\n",
    "            column_names = []\n",
    "            for i, col in enumerate(self.categorical):\n",
    "                column_names.extend([col + '_' + str(s) for s in self.ohe.categories_[i]])\n",
    "            self.column_names = column_names\n",
    "        X_cat_tr = pd.DataFrame(X_cat_tr, columns=self.column_names, index=X_copy.index)\n",
    "        X_other = X_copy.drop(columns=self.categorical)\n",
    "        X_copy = pd.concat([X_other, X_cat_tr], axis=1)\n",
    "        if self.drop_collinear:\n",
    "            to_drop = pd.Series(self.column_names, \n",
    "        index=self.column_names).apply(lambda x: x.endswith('_0'))[lambda x: x].index\n",
    "            X_copy.drop(columns=to_drop)\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(OneHot_df().fit(pre_proc(X_train)).transform(pre_proc(X_hold)).shape)\n",
    "\n",
    "''' Class 10 - find best normalizing transformation '''\n",
    "\n",
    "def get_shapiro_p(X):\n",
    "    _, p = shapiro(X)\n",
    "    return p\n",
    "\n",
    "class Find_Trans:\n",
    "    def __init__(self, threshold=10):\n",
    "        self.threshold = threshold\n",
    "        self.pvals = []\n",
    "        self.numerical = []\n",
    "        self.is_fitted = False\n",
    "        self.mms = MinMaxScaler()\n",
    "        self.trans_dict = {'no': lambda x: x,\n",
    "                           'x^2': lambda x: np.power(x, 2), \n",
    "                           'x^3': lambda x: np.power(x, 3), \n",
    "                           'log(x)': lambda x: np.log(x), \n",
    "                           #'exp(x)': lambda x: np.exp(x/10), \n",
    "                           'sqrt(x)': lambda x: np.sqrt(x)}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        counts = X_copy.apply(lambda x: x.value_counts().shape[0])\n",
    "        self.numerical = counts[counts > self.threshold].index.values\n",
    "        X_numer = X_copy[self.numerical]\n",
    "        idx = X_numer.index\n",
    "        X_numer = pd.DataFrame(self.mms.fit_transform(X_numer) + 0.01,\n",
    "                               columns=self.numerical,\n",
    "                               index=idx)\n",
    "        pvals = pd.DataFrame(X_numer.apply(get_shapiro_p), columns=['no'])\n",
    "        for name in self.trans_dict.keys():\n",
    "            if name not in pvals.columns:\n",
    "                pvals[name] = X_numer.apply(self.trans_dict[name]).apply(get_shapiro_p)\n",
    "        self.pvals = pvals\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_numer = X_copy[self.numerical]\n",
    "        idx = X_numer.index\n",
    "        X_numer = pd.DataFrame(self.mms.transform(X_numer) + 0.01,\n",
    "                               columns=self.numerical,\n",
    "                               index=idx)\n",
    "        best_transform = self.pvals.idxmax(axis=1)\n",
    "        best_transform = best_transform.map(self.trans_dict).to_dict()\n",
    "        X_numer = X_numer.apply(best_transform)\n",
    "        X_numer = X_numer.fillna(X_numer.min()-1)\n",
    "        for col in self.numerical:\n",
    "            X_copy[col] = X_numer[col]\n",
    "        return X_copy\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "print(Find_Trans().fit(pre_proc(X_train), y_train).transform(pre_proc(X_hold)).shape)\n",
    "\n",
    "\n",
    "''' Class 11 - find and drop outliers '''\n",
    "\n",
    "class DetectOut_df:\n",
    "    def __init__(self, method='IsolationForest', out_fraction=0.05, \n",
    "                 drop=True, random_state=17,\n",
    "                 kernel='rbf', shrink=True):\n",
    "        self.method = method\n",
    "        self.out_fraction = out_fraction\n",
    "        self.drop = drop\n",
    "        self.is_fitted = False\n",
    "        self.random_state = random_state\n",
    "        self.kernel = kernel\n",
    "        self.shrink = shrink\n",
    "        self.model = None\n",
    "        self.train_set = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.method == 'IsolationForest':\n",
    "            model = IsolationForest(random_state=self.random_state,\n",
    "                        n_estimators=100,\n",
    "                        max_features=0.9,\n",
    "                        contamination=self.out_fraction, #\n",
    "                        n_jobs=-1,\n",
    "                        behaviour='new')\n",
    "        if self.method == 'OneClassSVM':\n",
    "            model = OneClassSVM(kernel=self.kernel,\n",
    "                     nu=self.out_fraction,\n",
    "                     shrinking=self.shrink,\n",
    "                     gamma='scale'\n",
    "                    )\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        self.is_fitted = True\n",
    "        self.train_set = X.copy()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        ''' We shouldn't predict any outliers for test set '''\n",
    "        X_copy = X.copy()\n",
    "        X_copy['outlier'] = 1\n",
    "        X_copy['y'] = y.copy()\n",
    "        if self.train_set.equals(X):\n",
    "            X_copy['outlier'] = self.model.predict(X)\n",
    "        if self.drop:\n",
    "            X_copy = X_copy[X_copy['outlier'] == 1]\n",
    "            X_copy = X_copy.drop(columns=['outlier'])\n",
    "        y_copy = X_copy['y']\n",
    "        X_copy = X_copy.drop(columns=['y'])\n",
    "        return X_copy, y_copy\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        if not self.is_fitted:\n",
    "            self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "print(DetectOut_df().fit_transform(pre_proc(X_train), y_train)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8060754\ttotal: 30.2ms\tremaining: 15.1s\n",
      "100:\tlearn: 0.8924454\ttotal: 3.38s\tremaining: 13.4s\n",
      "200:\tlearn: 0.8949478\ttotal: 6.55s\tremaining: 9.75s\n",
      "300:\tlearn: 0.8966257\ttotal: 9.98s\tremaining: 6.6s\n",
      "400:\tlearn: 0.8992141\ttotal: 13s\tremaining: 3.21s\n",
      "499:\tlearn: 0.9012720\ttotal: 16.1s\tremaining: 0us\n",
      "Train ROC AUC: 0.9013\n",
      "Holdout ROC AUC: 0.8191\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cat = CatBoostClassifier(learning_rate=0.001, \n",
    "                                                iterations=500,\n",
    "                                                loss_function='CrossEntropy',\n",
    "                                                custom_metric='AUC:hints=skip_train~false',\n",
    "                                                eval_metric='AUC:hints=skip_train~false',\n",
    "                                                random_state=17,\n",
    "                                                rsm=0.1,\n",
    "                                                bootstrap_type='Bernoulli',\n",
    "                                                subsample=0.9,\n",
    "                                                verbose=100)\n",
    "pipe_cat = Pipeline([('drop_na', delete_nan),\n",
    "                     ('cat', cat)])\n",
    "\n",
    "pipe_cat.fit(X_train, y_train)\n",
    "\n",
    "#scores = cross_val_score(pipe_cat, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_cat.predict_proba(X_train)[:,1]))\n",
    "#print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_cat.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## После трансформации фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7889527\ttotal: 27ms\tremaining: 13.5s\n",
      "100:\tlearn: 0.8905381\ttotal: 2.92s\tremaining: 11.6s\n",
      "200:\tlearn: 0.8959516\ttotal: 6.2s\tremaining: 9.22s\n",
      "300:\tlearn: 0.8985831\ttotal: 8.78s\tremaining: 5.8s\n",
      "400:\tlearn: 0.9017381\ttotal: 11.4s\tremaining: 2.81s\n",
      "499:\tlearn: 0.9048930\ttotal: 14s\tremaining: 0us\n",
      "Train ROC AUC: 0.9049\n",
      "Holdout ROC AUC: 0.8198\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "\n",
    "cat = CatBoostClassifier(learning_rate=0.001, \n",
    "                                                iterations=500,\n",
    "                                                loss_function='CrossEntropy',\n",
    "                                                custom_metric='AUC:hints=skip_train~false',\n",
    "                                                eval_metric='AUC:hints=skip_train~false',\n",
    "                                                random_state=17,\n",
    "                                                rsm=0.1,\n",
    "                                                bootstrap_type='Bernoulli',\n",
    "                                                subsample=0.9,\n",
    "                                                verbose=100)\n",
    "pipe_cat = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('transform', Find_Trans(threshold=CAT_THRESHOLD)),\n",
    "                     ('cat', cat)])\n",
    "\n",
    "pipe_cat.fit(X_train, y_train)\n",
    "\n",
    "#scores = cross_val_score(pipe_cat, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_cat.predict_proba(X_train)[:,1]))\n",
    "#print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_cat.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7877042\ttotal: 26.2ms\tremaining: 13.1s\n",
      "100:\tlearn: 0.8896817\ttotal: 3.84s\tremaining: 15.2s\n",
      "200:\tlearn: 0.8913231\ttotal: 6.82s\tremaining: 10.2s\n",
      "300:\tlearn: 0.8931157\ttotal: 10.2s\tremaining: 6.75s\n",
      "400:\tlearn: 0.8954426\ttotal: 13s\tremaining: 3.2s\n",
      "499:\tlearn: 0.8980190\ttotal: 16.4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "pipe_cat.fit(X, y)\n",
    "\n",
    "submission = pd.read_csv(submission_file)\n",
    "submission['y'] = pipe_cat.predict_proba(X_test)[:,1]\n",
    "submission.to_csv('submission_cat_transform.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальная модель - 0.88414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8183259\ttotal: 278ms\tremaining: 2m 18s\n",
      "100:\tlearn: 0.9601761\ttotal: 33.6s\tremaining: 2m 12s\n",
      "200:\tlearn: 0.9649228\ttotal: 1m\tremaining: 1m 29s\n",
      "300:\tlearn: 0.9673679\ttotal: 1m 31s\tremaining: 1m\n",
      "400:\tlearn: 0.9700640\ttotal: 2m 12s\tremaining: 32.6s\n",
      "499:\tlearn: 0.9722581\ttotal: 2m 53s\tremaining: 0us\n",
      "Train ROC AUC: 0.9723\n",
      "Holdout ROC AUC: 0.8433\n",
      "CPU times: user 7min 27s, sys: 38.3 s, total: 8min 5s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' Let's finally play with Catboost '''\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CORR_THRESHOLD = 0.94\n",
    "CAT_THRESHOLD = 5 # <- and less unique values make feature categorical\n",
    "#OUT_FRACTION = 0.05 # <- percent of outliers\n",
    "#K = 400\n",
    "L2_LEAF_REG = 0.5 # <- regularization coefficient for CatBoost\n",
    "DEPTH = 10 # <- max tree depth for Catboost, can't be >10, or kernel will just die\n",
    "\n",
    "cat = CatBoostClassifier(learning_rate=0.001, \n",
    "                         iterations=500,\n",
    "                         loss_function='CrossEntropy',\n",
    "                         l2_leaf_reg=L2_LEAF_REG,\n",
    "                         depth=DEPTH,\n",
    "                         custom_metric='AUC:hints=skip_train~false', #CPU-only\n",
    "                         eval_metric='AUC:hints=skip_train~false', #CPU-only\n",
    "                         random_state=17,\n",
    "                         rsm=0.1, #CPU-only\n",
    "                         bootstrap_type='Bernoulli',\n",
    "                         subsample=0.9,\n",
    "                         #task_type='GPU',\n",
    "                         verbose=100)\n",
    "pipe_cat = Pipeline([('pre_proc', FunctionTransformer(pre_proc, validate=False)),\n",
    "                      ('drop_zero_var', Drop_zero_var()),\n",
    "                      ('drop_corr', Drop_corr(threshold=CORR_THRESHOLD)),\n",
    "                      ('lootme', LOOTME_df(threshold=CAT_THRESHOLD)),\n",
    "                      ('transform', Find_Trans(threshold=CAT_THRESHOLD)),\n",
    "                      #('feat_sel', SelectKBest(f_classif, K)),\n",
    "                      ('cat', cat)])\n",
    "\n",
    "pipe_cat.fit(X_train, y_train)\n",
    "\n",
    "#scores = cross_val_score(pipe_cat, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('Train ROC AUC: %.4f' % roc_auc_score(y_train, pipe_cat.predict_proba(X_train)[:,1]))\n",
    "#print('Cross-validation ROC AUC: mean %.4f, std %.4f' % (scores.mean(), scores.std()))\n",
    "print('Holdout ROC AUC: %.4f' % roc_auc_score(y_hold, pipe_cat.predict_proba(X_hold)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8581760\ttotal: 400ms\tremaining: 3m 19s\n",
      "100:\tlearn: 0.9522713\ttotal: 42.5s\tremaining: 2m 47s\n",
      "200:\tlearn: 0.9557651\ttotal: 1m 28s\tremaining: 2m 10s\n",
      "300:\tlearn: 0.9581447\ttotal: 2m 11s\tremaining: 1m 27s\n",
      "400:\tlearn: 0.9607246\ttotal: 2m 53s\tremaining: 42.9s\n",
      "499:\tlearn: 0.9631394\ttotal: 3m 27s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "pipe_cat.fit(X, y)\n",
    "\n",
    "submission = pd.read_csv(submission_file)\n",
    "submission['y'] = pipe_cat.predict_proba(X_test)[:,1]\n",
    "submission.to_csv('submission_cat_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
